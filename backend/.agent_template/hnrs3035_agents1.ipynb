{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use Google Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"31455a027435744e8\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDMVMGnKvDAXvO4N9R8iyimvuRR2XkZMxo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "search = GoogleSearchAPIWrapper(k=1)\n",
    "\n",
    "google_search_tool = Tool(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=search.run,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d38978bb-083d-4519-8d5f-c8dbfe1bb9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The latest in NOLA restaurants: A return on Magazine Street, French Quarter stunner closes Â· Klint Kubiak's new Saints offense was a draw to at least one free\\xa0...\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_search_tool.run(tool_input=\"current news in New Orleans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generate a Planning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "planning_prompt_template = \"\"\"\n",
    "System: You are an assistant at Louisiana State University to help with answering questions for students, faculty, and staff.\n",
    "\n",
    "Instructions:\n",
    "Your task is to answer a question. You will do so by either (1) directly answering the question, if you can based previous observations OR (2) by using a tool to get more information.\n",
    "\n",
    "Available Actions:\n",
    "- Google_Search_Tool: This tool allows you to search the web using Google and return short information snippets.\n",
    "- Weather_Tool: Allows you to get the current weather in a particular state or country.\n",
    "- Response_Tool: If you know the response, use this tool, which will format the response.\n",
    "\n",
    "Previous Questions, Actions, and Observations\n",
    "{context}\n",
    "\n",
    "QUESTION\n",
    "{question}\n",
    "\n",
    "Answer Format\n",
    "Your response must be a valid JSON structure with a \"Question\" field containing the question and an \"Action\" field containing the proposed action to take to answer the question.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",\n",
    "                 api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "planning_prompt = ChatPromptTemplate.from_template(planning_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "planning_chain = planning_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Who is the current LSU president',\n",
       " 'Action': 'Google_Search_Tool'}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planning_chain.invoke({\"question\": \"Who is the current LSU president\",\n",
    "                       \"context\": \"No previous communication\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Defining Tool Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tool_inputs = {\n",
    "    \"Google_Search_Tool\": {\"tool_input\": \"(str) The query that will be used for Google Search\"},\n",
    "    \"Weather_Tool\": {\"city\": \"(str) The city in which we want to determine the weather\",\n",
    "                     \"state\": \"(str) The two character state code of the city\",\n",
    "                     \"country\": \"(str) The two character code of country, e.g. United States is 'US'\"},\n",
    "    \"Response_Tool\": {\"response\": \"(str) The final response to the user's question.\"}\n",
    "}\n",
    "\n",
    "\n",
    "def format_tool_prompt_template(tool_name):\n",
    "    tool_args = tool_inputs[tool_name]\n",
    "    s = f\"\"\"The tool \"{tool_name}\" accepts {len(tool_args.keys())} keyword arguments, listed below with descriptions:\n",
    "\n",
    "\"\"\"\n",
    "    for k in tool_args.keys():\n",
    "        s += f\"\\t{k}: {tool_args[k]}\\n\"\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use an LLM to determine the arguments to our tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tool_exec_prompt_template = \"\"\"\n",
    "General Instruction: We wish to use a tool to answer a question or execute an instruction. You are to generate a JSON dictionary (single line, no indents) containing the values for input arguments to that tool based on the question or instruction:\n",
    "\n",
    "Tool Description:\n",
    "{tool_prompt}\n",
    "\n",
    "Question or Instruction:\n",
    "{question}\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "tool_exec_prompt = ChatPromptTemplate.from_template(tool_exec_prompt_template)\n",
    "\n",
    "tool_exec_chain = tool_exec_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Baton Rouge', 'state': 'LA', 'country': 'US'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_chain.invoke({\"question\": \"What is the weather today in Baton Rouge?\",\n",
    "                        \"tool_prompt\": format_tool_prompt_template(\"Weather_Tool\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Incorporate Weather Data Using OpenWeatherMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyowm import OWM\n",
    "owm = OWM('5cec79482318850a1df95f5a3165369b')\n",
    "mgr = owm.weather_manager()\n",
    "reg = owm.city_id_registry()\n",
    "mgr = owm.weather_manager()\n",
    "\n",
    "def get_weather(city, state, country):\n",
    "    id = reg.locations_for(city, state=state, country=country, matching='exact')[0].id\n",
    "\n",
    "    weather = mgr.weather_at_id(id).weather\n",
    "\n",
    "    weather_str = f'Temperature = {weather.temperature(\"fahrenheit\")[\"temp\"]} F, Feels Like Temperature = {weather.temperature(\"fahrenheit\")[\"feels_like\"]} F, Humidity = {weather.humidity} %, Detailed Status = {weather.detailed_status}, Wind = {weather.wind(unit=\"miles_hour\")[\"speed\"]} mph at {weather.wind(unit=\"miles_hour\")[\"deg\"]} degrees'\n",
    "    return weather_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Temperature = 70.9 F, Feels Like Temperature = 69.19 F, Humidity = 32 %, Detailed Status = overcast clouds, Wind = 6.9121446 mph at 300 degrees'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather(city=\"Baton Rouge\", state=\"LA\", country=\"US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define Function to Execute Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def execute_tool(tool_name, tool_kwargs):\n",
    "    if tool_name == \"Weather_Tool\":\n",
    "        output = get_weather(**tool_kwargs)\n",
    "    elif tool_name == \"Google_Search_Tool\":\n",
    "        output = google_search_tool(**tool_kwargs)\n",
    "    elif tool_name == \"Response_Tool\":\n",
    "        return tool_kwargs[\"response\"]\n",
    "    else:\n",
    "        print(\"Fail\")\n",
    "        output = \"None\"\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Is today a nice day to play a football game outside?',\n",
       " 'Action': 'Weather_Tool'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planning_chain.invoke({\"question\": \"Is today a nice day to play a football game outside?\",\n",
    "                       \"context\": \"No previous communication\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Define Chain to Format Final Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_response_template = \"\"\"\n",
    "Based on the following information, answer the question:\n",
    "Information:\n",
    "{information}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "final_response_prompt = ChatPromptTemplate.from_template(final_response_template)\n",
    "\n",
    "final_response_chain = final_response_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': 'Is today a nice day to play a football game outside in Baton Rouge?', 'Action': 'Weather_Tool'}\n",
      "{'city': 'Baton Rouge', 'state': 'LA', 'country': 'US'}\n",
      "Temperature = 70.99 F, Feels Like Temperature = 69.24 F, Humidity = 31 %, Detailed Status = overcast clouds, Wind = 6.9121446 mph at 300 degrees\n",
      "\n",
      "\n",
      "Final Response:\n",
      "Yes, today seems like a good day to play a football game outside in Baton Rouge. The temperature is comfortable, the humidity is not too high, and there are overcast clouds which may provide some shade. The wind is moderate at 6.9 mph, so it shouldn't affect gameplay too much. Enjoy the game!\n"
     ]
    }
   ],
   "source": [
    "my_question = \"Is today a nice day to play a football game outside in Baton Rouge?\"\n",
    "plan = planning_chain.invoke({\"question\": my_question, \"context\": \"No previous communication\"})\n",
    "print(plan)\n",
    "exec_data = tool_exec_chain.invoke({\"question\": my_question,\n",
    "                                    \"tool_prompt\": format_tool_prompt_template(plan[\"Action\"])})\n",
    "print(exec_data)\n",
    "tool_output = execute_tool(plan[\"Action\"], exec_data)\n",
    "print(tool_output)\n",
    "print('\\n\\nFinal Response:')\n",
    "print(final_response_chain.invoke({\"question\": my_question,\n",
    "                                   \"information\": tool_output}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': \"Who is LSU's president?\", 'Action': 'Google_Search_Tool'}\n",
      "{'tool_input': 'LSU president'}\n",
      "LSU President William F. Tate IV takes on students in a friendly putting competition as the Fall 2023 semester begins.\n",
      "\n",
      "\n",
      "Final Response:\n",
      "LSU's president is William F. Tate IV.\n"
     ]
    }
   ],
   "source": [
    "my_question = \"Who is LSU's president?\"\n",
    "plan = planning_chain.invoke({\"question\": my_question, \"context\": \"No previous communication\"})\n",
    "print(plan)\n",
    "exec_data = tool_exec_chain.invoke({\"question\": my_question,\n",
    "                                    \"tool_prompt\": format_tool_prompt_template(plan[\"Action\"])})\n",
    "print(exec_data)\n",
    "tool_output = execute_tool(plan[\"Action\"], exec_data)\n",
    "print(tool_output)\n",
    "print('\\n\\nFinal Response:')\n",
    "print(final_response_chain.invoke({\"question\": my_question,\n",
    "                                   \"information\": tool_output}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8850806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
